# çš®è‚¤ç—…åˆ†ç±»é¡¹ç›®è®­ç»ƒé—®é¢˜åˆ†æä¸è§£å†³æ–¹æ¡ˆ

## é—®é¢˜æè¿°

æ ¹æ®æä¾›çš„lossæ›²çº¿å›¾ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°äº†æ˜æ˜¾çš„å¼‚å¸¸ç°è±¡ï¼š
- **è®­ç»ƒloss**ï¼šä»0.16å¿«é€Ÿä¸‹é™åˆ°æ¥è¿‘0ï¼Œè¡¨ç°æ­£å¸¸
- **éªŒè¯loss**ï¼šä»0.8å¼€å§‹æŒç»­ä¸Šå‡åˆ°2.8ï¼Œæ˜æ˜¾è¿‡æ‹Ÿåˆ

## æ•°æ®é›†ä¿¡æ¯
- Progressive: RGBå’ŒUVå„293å¼ 
- Stable: RGBå’ŒUVå„307å¼   
- æ€»è®¡ï¼š600å¼ å›¾åƒå¯¹
- åˆ†ç±»ä»»åŠ¡ï¼šäºŒåˆ†ç±»ï¼ˆstable vs progressiveï¼‰

## ä¸»è¦é—®é¢˜åˆ†æ

### 1. ğŸ”´ **æ•°æ®å¢å¼ºä¸ä¸€è‡´é—®é¢˜ï¼ˆæ ¸å¿ƒé—®é¢˜ï¼‰**

**é—®é¢˜æè¿°ï¼š**
è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ•°æ®å¤„ç†æ–¹å¼å­˜åœ¨ä¸¥é‡ä¸ä¸€è‡´ï¼š

- **è®­ç»ƒé›†**ï¼šä½¿ç”¨`FlattenedAugmentedDataset`ï¼Œæ¯ä¸ªåŸå§‹æ ·æœ¬ç”Ÿæˆ6ä¸ªå¢å¼ºç‰ˆæœ¬
- **éªŒè¯é›†**ï¼šä½¿ç”¨åŸå§‹`DualModalDataset`ï¼Œä½†åœ¨éªŒè¯æ—¶é”™è¯¯åœ°è°ƒç”¨äº†`squeeze(1)`

**ä»£ç é—®é¢˜ä½ç½®ï¼š**
```python
# train.py ç¬¬92-94è¡Œ
rgb_tensor = rgb_tensor.squeeze(1).to(device)  # é”™è¯¯ï¼
uv_tensor = uv_tensor.squeeze(1).to(device)
```

**é—®é¢˜å½±å“ï¼š**
- éªŒè¯é›†çš„tensorç»´åº¦å¤„ç†é”™è¯¯ï¼Œå¯èƒ½å¯¼è‡´æ¨¡å‹è¾“å…¥å¼‚å¸¸
- è®­ç»ƒæ—¶çœ‹åˆ°çš„æ˜¯å¢å¼ºæ•°æ®ï¼ŒéªŒè¯æ—¶çœ‹åˆ°çš„æ˜¯åŸå§‹æ•°æ®ï¼Œåˆ†å¸ƒä¸åŒ¹é…

### 2. ğŸ”´ **æ•°æ®é‡è¿‡å°å¯¼è‡´è¿‡æ‹Ÿåˆ**

**é—®é¢˜æè¿°ï¼š**
- åŸå§‹æ•°æ®ä»…600å¼ ï¼ŒæŒ‰7:1.5:1.5åˆ†å‰²åè®­ç»ƒé›†çº¦420å¼ 
- ä½¿ç”¨6å€æ•°æ®å¢å¼ºåè®­ç»ƒé›†å˜æˆ2520å¼ ï¼Œä½†æœ¬è´¨ä¸Šä»æ˜¯420å¼ åŸå§‹å›¾åƒ
- éªŒè¯é›†ä»…çº¦90å¼ ï¼Œæ ·æœ¬é‡è¿‡å°ï¼Œå®¹æ˜“äº§ç”Ÿä¸ç¨³å®šçš„éªŒè¯ç»“æœ

### 3. ğŸ”´ **æ¨¡å‹å¤æ‚åº¦è¿‡é«˜**

**é—®é¢˜æè¿°ï¼š**
- ä½¿ç”¨åŒåˆ†æ”¯InceptionV3ï¼Œå‚æ•°é‡å·¨å¤§ï¼ˆçº¦44Må‚æ•°ï¼‰
- è¾“å…¥åˆ†è¾¨ç‡1088Ã—1088ï¼Œè®¡ç®—é‡æå¤§
- å¯¹äº600å¼ å°æ•°æ®é›†æ¥è¯´ï¼Œæ¨¡å‹è¿‡äºå¤æ‚

### 4. ğŸ”´ **å­¦ä¹ ç‡å’Œä¼˜åŒ–å™¨é…ç½®é—®é¢˜**

**é—®é¢˜æè¿°ï¼š**
- å­¦ä¹ ç‡1e-4å¯¹äºå°æ•°æ®é›†å¯èƒ½è¿‡é«˜
- ä½¿ç”¨Adamä¼˜åŒ–å™¨ä½†æ²¡æœ‰åˆé€‚çš„å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥
- CosineAnnealingLRå¯èƒ½ä¸é€‚åˆè¿™ç§å°æ•°æ®é›†åœºæ™¯

## è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆä¸€ï¼šå¿«é€Ÿä¿®å¤ï¼ˆæ¨èä¼˜å…ˆå°è¯•ï¼‰

#### 1. ä¿®å¤éªŒè¯é›†æ•°æ®å¤„ç†
```python
# ä¿®æ”¹train.pyç¬¬92-94è¡Œ
with torch.no_grad():
    for rgb_tensor, uv_tensor, label_tensor in val_loader:
        # ç§»é™¤é”™è¯¯çš„squeezeæ“ä½œ
        rgb_tensor = rgb_tensor.to(device)
        uv_tensor = uv_tensor.to(device)
        label_tensor = label_tensor.to(device)
```

#### 2. é™ä½æ¨¡å‹å¤æ‚åº¦
```python
# å‡å°è¾“å…¥åˆ†è¾¨ç‡
train_transform = PairedTrainTransform(resize_shorter=512, output_size=(512, 512))
val_transform = PairedEvalTransform(resize_shorter=512, output_size=(512, 512))

# å‡å°batch size
train_loader = DataLoader(flat_train_dataset, batch_size=4, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)
```

#### 3. è°ƒæ•´è®­ç»ƒå‚æ•°
```python
# é™ä½å­¦ä¹ ç‡
optimizer = optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-3)

# å¢åŠ æ­£åˆ™åŒ–
criterion = nn.CrossEntropyLoss(label_smoothing=0.2)

# æ—©åœæœºåˆ¶
patience = 10
best_val_loss = float('inf')
patience_counter = 0
```

### æ–¹æ¡ˆäºŒï¼šæ•°æ®å¢å¼ºç­–ç•¥ä¼˜åŒ–

#### 1. å‡å°‘è¿‡åº¦å¢å¼º
```python
# ä¿®æ”¹tranform.pyï¼Œå‡å°‘å¢å¼ºå€æ•°
def __call__(self, rgb_img, uv_img):
    # åªä¿ç•™å¿…è¦çš„å¢å¼ºï¼šåŸå›¾ã€æ°´å¹³ç¿»è½¬ã€å‚ç›´ç¿»è½¬
    imgs_rgb, imgs_uv = [], []
    
    # åŸå›¾
    imgs_rgb.append(F.to_tensor(rgb_img))
    imgs_uv.append(F.to_tensor(uv_img))
    
    # æ°´å¹³ç¿»è½¬
    imgs_rgb.append(F.to_tensor(F.hflip(rgb_img)))
    imgs_uv.append(F.to_tensor(F.hflip(uv_img)))
    
    # å‚ç›´ç¿»è½¬  
    imgs_rgb.append(F.to_tensor(F.vflip(rgb_img)))
    imgs_uv.append(F.to_tensor(F.vflip(uv_img)))
    
    return imgs_rgb, imgs_uv
```

#### 2. éªŒè¯é›†ä¹Ÿä½¿ç”¨è½»å¾®å¢å¼º
```python
# ä¸ºéªŒè¯é›†æ·»åŠ TTAï¼ˆTest Time Augmentationï¼‰
class PairedEvalTransform:
    def __call__(self, rgb_img, uv_img):
        # è¿”å›åŸå›¾å’Œæ°´å¹³ç¿»è½¬ï¼Œå–å¹³å‡é¢„æµ‹
        rgb_orig = F.to_tensor(F.center_crop(self.resize_shorter_edge(rgb_img), self.output_size))
        uv_orig = F.to_tensor(F.center_crop(self.resize_shorter_edge(uv_img), self.output_size))
        
        rgb_flip = F.to_tensor(F.hflip(F.center_crop(self.resize_shorter_edge(rgb_img), self.output_size)))
        uv_flip = F.to_tensor(F.hflip(F.center_crop(self.resize_shorter_edge(uv_img), self.output_size)))
        
        return [rgb_orig, rgb_flip], [uv_orig, uv_flip]
```

### æ–¹æ¡ˆä¸‰ï¼šæ¨¡å‹æ¶æ„ä¼˜åŒ–

#### 1. ä½¿ç”¨æ›´è½»é‡çš„backbone
```python
# æ›¿æ¢ä¸ºResNet18æˆ–EfficientNet-B0
class DualBranchLightweight(nn.Module):
    def __init__(self, num_classes=2, weight_path=None):
        super().__init__()
        # ä½¿ç”¨æ›´è½»é‡çš„backbone
        self.rgb_branch = timm.create_model("resnet18", pretrained=True, num_classes=0)
        self.uv_branch = timm.create_model("resnet18", pretrained=True, num_classes=0)
        
        # ç®€åŒ–åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Linear(512 * 2, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )
```

#### 2. æ·»åŠ æ›´å¼ºçš„æ­£åˆ™åŒ–
```python
# åœ¨æ¨¡å‹ä¸­æ·»åŠ Dropout
self.classifier = nn.Sequential(
    nn.Flatten(),
    nn.Dropout(0.5),  # å¢åŠ dropout
    nn.Linear(512 * 7 * 7, 256),
    nn.ReLU(),
    nn.Dropout(0.5),  # å†æ¬¡dropout
    nn.Linear(256, num_classes)
)
```

## å®æ–½å»ºè®®

### ç«‹å³æ‰§è¡Œï¼ˆä¼˜å…ˆçº§ï¼šé«˜ï¼‰
1. ä¿®å¤éªŒè¯é›†æ•°æ®å¤„ç†çš„squeezeé”™è¯¯
2. é™ä½è¾“å…¥åˆ†è¾¨ç‡åˆ°512Ã—512
3. å‡å°batch sizeåˆ°4
4. é™ä½å­¦ä¹ ç‡åˆ°5e-5

### çŸ­æœŸä¼˜åŒ–ï¼ˆä¼˜å…ˆçº§ï¼šä¸­ï¼‰
1. å‡å°‘æ•°æ®å¢å¼ºå€æ•°ä»6å€åˆ°3å€
2. å¢åŠ label smoothingåˆ°0.2
3. å®æ–½æ—©åœæœºåˆ¶

### é•¿æœŸæ”¹è¿›ï¼ˆä¼˜å…ˆçº§ï¼šä½ï¼‰
1. æ”¶é›†æ›´å¤šæ•°æ®
2. å°è¯•æ›´è½»é‡çš„æ¨¡å‹æ¶æ„
3. å®æ–½äº¤å‰éªŒè¯

## é¢„æœŸæ•ˆæœ

å®æ–½ä¸Šè¿°ä¿®å¤åï¼Œé¢„æœŸçœ‹åˆ°ï¼š
- éªŒè¯lossä¸å†æŒç»­ä¸Šå‡
- è®­ç»ƒå’ŒéªŒè¯lossæ›²çº¿æ›´åŠ æ¥è¿‘
- æ¨¡å‹æ³›åŒ–èƒ½åŠ›æå‡
- è®­ç»ƒç¨³å®šæ€§å¢å¼º

## ç›‘æ§æŒ‡æ ‡

è®­ç»ƒè¿‡ç¨‹ä¸­é‡ç‚¹å…³æ³¨ï¼š
- è®­ç»ƒlosså’ŒéªŒè¯lossçš„å·®è·
- éªŒè¯å‡†ç¡®ç‡çš„ç¨³å®šæ€§
- ç‰¹å¼‚æ€§(Specificity)å’Œç²¾ç¡®ç‡(Precision)çš„å¹³è¡¡
- æ··æ·†çŸ©é˜µçš„å¯¹è§’çº¿å…ƒç´ 

## å…·ä½“ä»£ç ä¿®å¤ç¤ºä¾‹

### 1. ä¿®å¤train.pyä¸­çš„éªŒè¯å¾ªç¯

**åŸä»£ç ï¼ˆç¬¬91-96è¡Œï¼‰ï¼š**
```python
with torch.no_grad():
    for rgb_tensor, uv_tensor, label_tensor in val_loader:
        rgb_tensor = rgb_tensor.squeeze(1).to(device)  # âŒ é”™è¯¯
        uv_tensor = uv_tensor.squeeze(1).to(device)    # âŒ é”™è¯¯
        label_tensor = label_tensor.to(device)
```

**ä¿®å¤åï¼š**
```python
with torch.no_grad():
    for rgb_tensor, uv_tensor, label_tensor in val_loader:
        # éªŒè¯é›†è¿”å›çš„æ˜¯ [B, 1, C, H, W]ï¼Œéœ€è¦æ­£ç¡®å¤„ç†
        if rgb_tensor.dim() == 5:  # å¦‚æœæœ‰é¢å¤–ç»´åº¦æ‰squeeze
            rgb_tensor = rgb_tensor.squeeze(1)
            uv_tensor = uv_tensor.squeeze(1)
        rgb_tensor = rgb_tensor.to(device)
        uv_tensor = uv_tensor.to(device)
        label_tensor = label_tensor.to(device)
```

### 2. ä¼˜åŒ–è®­ç»ƒå‚æ•°é…ç½®

**åœ¨train.pyä¸­æ·»åŠ æ—©åœæœºåˆ¶ï¼š**
```python
# åœ¨è®­ç»ƒå¾ªç¯å‰æ·»åŠ 
best_val_loss = float('inf')
patience = 15
patience_counter = 0
early_stop = False

# åœ¨éªŒè¯å¾ªç¯åæ·»åŠ 
if val_loss < best_val_loss:
    best_val_loss = val_loss
    patience_counter = 0
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    torch.save(model.state_dict(), 'best_model.pth')
else:
    patience_counter += 1
    if patience_counter >= patience:
        print(f"Early stopping at epoch {epoch+1}")
        early_stop = True

if early_stop:
    break
```

### 3. æ•°æ®å¢å¼ºä¼˜åŒ–

**åˆ›å»ºæ–°çš„è½»é‡å¢å¼ºç­–ç•¥ï¼ˆtranform.pyï¼‰ï¼š**
```python
class PairedLightTrainTransform:
    def __init__(self, resize_shorter=512, output_size=(512, 512)):
        self.resize_shorter = resize_shorter
        self.output_size = output_size

    def resize_shorter_edge(self, img):
        w, h = img.size
        if w < h:
            new_w = self.resize_shorter
            new_h = int(h * self.resize_shorter / w)
        else:
            new_h = self.resize_shorter
            new_w = int(w * self.resize_shorter / h)
        return F.resize(img, (new_h, new_w))

    def __call__(self, rgb_img, uv_img):
        rgb_img = self.resize_shorter_edge(rgb_img)
        uv_img = self.resize_shorter_edge(uv_img)

        rgb_img = F.center_crop(rgb_img, self.output_size)
        uv_img = F.center_crop(uv_img, self.output_size)

        imgs_rgb, imgs_uv = [], []

        # åŸå›¾
        imgs_rgb.append(F.to_tensor(rgb_img))
        imgs_uv.append(F.to_tensor(uv_img))

        # æ°´å¹³ç¿»è½¬
        imgs_rgb.append(F.to_tensor(F.hflip(rgb_img)))
        imgs_uv.append(F.to_tensor(F.hflip(uv_img)))

        # å‚ç›´ç¿»è½¬
        imgs_rgb.append(F.to_tensor(F.vflip(rgb_img)))
        imgs_uv.append(F.to_tensor(F.vflip(uv_img)))

        return imgs_rgb, imgs_uv
```

## ç´§æ€¥ä¿®å¤æ¸…å•

### âœ… ç¬¬ä¸€æ­¥ï¼šç«‹å³ä¿®å¤éªŒè¯æ•°æ®å¤„ç†
1. ä¿®æ”¹train.pyç¬¬92-94è¡Œçš„squeezeæ“ä½œ
2. é™ä½åˆ†è¾¨ç‡åˆ°512Ã—512
3. å‡å°batch_sizeåˆ°4

### âœ… ç¬¬äºŒæ­¥ï¼šä¼˜åŒ–è®­ç»ƒç­–ç•¥
1. å­¦ä¹ ç‡æ”¹ä¸º5e-5
2. å¢åŠ weight_decayåˆ°1e-3
3. label_smoothingæ”¹ä¸º0.2
4. æ·»åŠ æ—©åœæœºåˆ¶

### âœ… ç¬¬ä¸‰æ­¥ï¼šæ•°æ®å¢å¼ºè°ƒæ•´
1. å‡å°‘å¢å¼ºå€æ•°ä»6å€åˆ°3å€
2. ç§»é™¤è¿‡äºæ¿€è¿›çš„éšæœºæ—‹è½¬å’Œè£å‰ª
3. ä¿ç•™åŸºæœ¬çš„ç¿»è½¬æ“ä½œ

## é¢„æœŸæ”¹è¿›æ•ˆæœ

ä¿®å¤ååº”è¯¥çœ‹åˆ°ï¼š
- âœ… éªŒè¯lossä¸å†å•è°ƒä¸Šå‡
- âœ… è®­ç»ƒå’ŒéªŒè¯losså·®è·ç¼©å°
- âœ… éªŒè¯å‡†ç¡®ç‡æ›´åŠ ç¨³å®š
- âœ… æ•´ä½“è®­ç»ƒè¿‡ç¨‹æ›´åŠ å¹³æ»‘

å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œå»ºè®®è€ƒè™‘ï¼š
1. è¿›ä¸€æ­¥å‡å°æ¨¡å‹å¤æ‚åº¦ï¼ˆä½¿ç”¨ResNet18ï¼‰
2. å¢åŠ æ•°æ®æ”¶é›†
3. ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè¿ç§»å­¦ä¹ 
4. å®æ–½kæŠ˜äº¤å‰éªŒè¯

## æä¾›çš„è§£å†³æ–¹æ¡ˆæ–‡ä»¶

æˆ‘å·²ç»ä¸ºä½ åˆ›å»ºäº†ä»¥ä¸‹æ–‡ä»¶æ¥è§£å†³è®­ç»ƒé—®é¢˜ï¼š

### 1. ğŸ“„ `train_fixed.py` - ä¿®å¤ç‰ˆè®­ç»ƒè„šæœ¬
- ä¿®å¤äº†éªŒè¯é›†æ•°æ®å¤„ç†çš„squeezeé”™è¯¯
- é™ä½äº†è¾“å…¥åˆ†è¾¨ç‡åˆ°512Ã—512
- æ·»åŠ äº†æ—©åœæœºåˆ¶å’Œæ¢¯åº¦è£å‰ª
- ä¼˜åŒ–äº†å­¦ä¹ ç‡å’Œæ­£åˆ™åŒ–å‚æ•°

### 2. ğŸ“„ `train_lightweight.py` - è½»é‡åŒ–è®­ç»ƒè„šæœ¬
- ä½¿ç”¨è½»é‡åŒ–æ¨¡å‹æ¶æ„
- ä¸“ä¸ºå°æ•°æ®é›†ä¼˜åŒ–
- åŒ…å«å®Œæ•´çš„è®­ç»ƒç›‘æ§å’Œä¿å­˜æœºåˆ¶
- æ”¯æŒå¤šç§æ¨¡å‹å’Œå¢å¼ºç­–ç•¥é€‰æ‹©

### 3. ğŸ“„ `model_light.py` - è½»é‡åŒ–æ¨¡å‹
- `DualBranchLightweight`: ä½¿ç”¨ResNet18ï¼Œçº¦22Må‚æ•°
- `DualBranchMini`: ä½¿ç”¨MobileNetV3ï¼Œçº¦10Må‚æ•°
- `DualBranchEfficientNet`: ä½¿ç”¨EfficientNet-B0ï¼Œçº¦10Må‚æ•°

### 4. ğŸ“„ `transform_light.py` - ä¼˜åŒ–çš„æ•°æ®å¢å¼º
- `PairedMinimalTrainTransform`: æœ€å°å¢å¼º(2å€)
- `PairedLightTrainTransform`: è½»é‡å¢å¼º(3å€)
- `PairedStableTrainTransform`: ç¨³å®šå¢å¼º(4å€)

## ä½¿ç”¨å»ºè®®

### ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆæ¨èï¼‰
```bash
# 1. ä½¿ç”¨è½»é‡åŒ–è®­ç»ƒè„šæœ¬
python train_lightweight.py

# 2. æŸ¥çœ‹è®­ç»ƒæ›²çº¿
tensorboard --logdir runs_lightweight --port=6007
```

### ğŸ”§ å¦‚æœä»æœ‰é—®é¢˜ï¼Œå°è¯•ä»¥ä¸‹é…ç½®ï¼š

**æå°æ•°æ®é›†é…ç½®ï¼š**
```python
config = {
    'model_type': 'mini',        # ä½¿ç”¨æœ€å°æ¨¡å‹
    'augmentation': 'minimal',   # æœ€å°å¢å¼º
    'input_size': 256,          # æ›´å°åˆ†è¾¨ç‡
    'batch_size': 4,            # æ›´å°batch
    'learning_rate': 5e-5       # æ›´å°å­¦ä¹ ç‡
}
```

**æ ‡å‡†é…ç½®ï¼š**
```python
config = {
    'model_type': 'lightweight', # è½»é‡åŒ–æ¨¡å‹
    'augmentation': 'light',     # è½»é‡å¢å¼º
    'input_size': 384,          # ä¸­ç­‰åˆ†è¾¨ç‡
    'batch_size': 8,            # æ ‡å‡†batch
    'learning_rate': 1e-4       # æ ‡å‡†å­¦ä¹ ç‡
}
```

### ğŸ“Š ç›‘æ§æŒ‡æ ‡
è®­ç»ƒè¿‡ç¨‹ä¸­é‡ç‚¹è§‚å¯Ÿï¼š
- è®­ç»ƒå’ŒéªŒè¯lossçš„æ”¶æ•›è¶‹åŠ¿
- ä¸¤è€…ä¹‹é—´çš„å·®è·ï¼ˆè¿‡æ‹ŸåˆæŒ‡æ ‡ï¼‰
- F1åˆ†æ•°çš„ç¨³å®šæ€§
- å­¦ä¹ ç‡è¡°å‡æƒ…å†µ

### ğŸ¯ é¢„æœŸæ•ˆæœ
ä½¿ç”¨è½»é‡åŒ–æ–¹æ¡ˆååº”è¯¥çœ‹åˆ°ï¼š
- âœ… éªŒè¯lossä¸å†æŒç»­ä¸Šå‡
- âœ… è®­ç»ƒæ›´åŠ ç¨³å®šï¼Œæ”¶æ•›æ›´å¿«
- âœ… å†…å­˜å ç”¨æ˜¾è‘—é™ä½
- âœ… è®­ç»ƒæ—¶é—´ç¼©çŸ­50%ä»¥ä¸Š

## æ•…éšœæ’é™¤

å¦‚æœè®­ç»ƒä»ç„¶ä¸ç¨³å®šï¼š

1. **è¿›ä¸€æ­¥é™ä½å¤æ‚åº¦**ï¼š
   - ä½¿ç”¨`model_type='mini'`
   - è®¾ç½®`input_size=256`
   - å‡å°‘åˆ°`batch_size=2`

2. **æ£€æŸ¥æ•°æ®è´¨é‡**ï¼š
   - ç¡®è®¤RGBå’ŒUVå›¾åƒå¯¹åº”æ­£ç¡®
   - æ£€æŸ¥å›¾åƒæ˜¯å¦æŸå
   - éªŒè¯æ ‡ç­¾åˆ†å¸ƒæ˜¯å¦å¹³è¡¡

3. **è°ƒè¯•æ¨¡å¼**ï¼š
   - è®¾ç½®`num_epochs=10`è¿›è¡Œå¿«é€Ÿæµ‹è¯•
   - ä½¿ç”¨`augmentation='minimal'`å‡å°‘å˜é‡

4. **ç¡¬ä»¶é™åˆ¶**ï¼š
   - å¦‚æœGPUå†…å­˜ä¸è¶³ï¼Œé™ä½`input_size`å’Œ`batch_size`
   - è€ƒè™‘ä½¿ç”¨CPUè®­ç»ƒï¼ˆè™½ç„¶è¾ƒæ…¢ï¼‰
